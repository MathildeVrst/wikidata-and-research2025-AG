---
title: "Authoritative Practices and Collective Validation: Wikidata within the Collaborative Digital Edition of the Greek Anthology"
author: 
- Mathilde Verstraete
- Maxime Guénette 
- Marcello Vitali-Rosati 
keywords: Greek Anthology, Digital Philology, Authority, Wikidata, Collective Intelligence
lang: en
format: pdf
abstract: "As collaborative digital platforms become more common in cultural and Digital Humanities projects, the role of non-experts and their contributions to these platforms is shifting. Platforms such as Wikidata invite a reconsideration of where authority lies: not solely in the hands of experts, but also within a wider community of contributors who bring diverse forms of expertise. This development challenges hierarchies in academic and cultural institutions and raises new questions about validation, trust and collaborative knowledge production. In this paper, we explore these questions through the lens of the *Anthologia Graeca* project, where the integration of Wikidata has become a way of rethinking editorial authority as a shared process."
abstract-title: Abstract
bibliography: ref.bib
csl: chicago-author-date.csl 
---
Keywords: Greek Anthology, Digital Philology, Authority, Wikidata, Collective Intelligence

## Introduction 

The management and preservation of research data in the Humanities increasingly raise questions concerning sustainability, accessibility, sharing, and validation. In this context, Wikidata emerges as a powerful and collaborative tool<!--@Max ; tool ou platform ?-->. By challenging traditional models in which researchers act simultaneously as producers and gatekeepers of authority, Wikidata reconfigures these issues and fosters new paradigms of collaborative knowledge production.

Within the framework of Digital Humanities (DH), which emphasizes open processes, data interoperability and collective engagement<!--@Max : t'es d'accord ?-->, Wikidata functions as a knowledge base<!--@Max, j'enlèverais "for publication", pas sûre que ça soit pertinent-->, enabling a sort of collective verification and semantic linking of information. Unlike traditional academic publishing, where authority is centralised and often restricted to established institutions or recognised experts, Wikidata operates through a model of continuous, multilingual, and community-bases editing that promotes the dissemination of free and accessible knowledge globally. This paradigmatic shift invites a fundamental rethinking of authority, editorial responsibility, and the epistemological foundations of data.

How, then, can *expert-led* projects --- whether developed by academics, government agencies or GLAM institutions (Galleries, Libraries, Archives and Museums) --- work with a generalist platform such as Wikidata to generate new forms of knowledge? How do these hybrid models, which combine scholarly expertise with public participation, challenge traditional boundaries between academic and amateur contributors, and between knowledge production and validation?

In this article, we explore how the infrastructure and logic of Wikidata can be integrated into DH projects, focusing on the *Anthologia Graeca* (AG) project, a collaborative digital edition of the *Greek Anthology*. After outlining the role of Wikidata in DH initiatives<!-- @max, je mettrais pas la suite, peur qu'on nous reproche de pas avoir fait d'analyse quali: and examining its perception within academia-->, we turn to our case study to analyse how Wikidata is embedded in the data model of the AG project and contributes to the emergence of new spaces of knowledge creation. Finally, we reflect on the role of authority and collective intelligence in shaping such projects and reflections.

<!--@max: est-ce qu'on a une idée de l'importance des connus concernant les auteurs anciens sur wikidata ? Si pauvre, notre projet ajoute une plus value importante quali- et quantitativement (?) -->

## Wikidata and Digital Humanities

Since its creation in 2012, Wikidata has gradually become one of the most significant knowledge graphs on the Web. As structured data plays an increasingly central role in the organization, retrieval, and circulation of information online, Wikidata occupies a pivotal position in shaping how knowledge is represented, accessed, and reused.

As a result, Wikidata has gained popularity within the field of DH. Although there has been --- and to some extent, continues to be --- skepticism<!--@Max: ref? ou même pointer vers une ref qui reprend le débat ?--> about its quality and potential as a scholarly resource, recent studies have shown that it is now widely adopted across DH projects [@cookUsesWikidataGalleries2019; @zhaoSystematicReviewWikidata2023]. Within this context, it is primarily used as a *content provider* --- a means to access, publish, or disseminate Linked Open Data (LOD) while avoiding many of the technical and financial constraints traditionally associated with the Semantic Web.

For institutions in the GLAM sector (Galleries, Libraries, Archives, and Museums), Wikidata serves a somewhat different role: as a *publishing platform* and a *tool for metadata curation*. Because digitization strategies have historically been developed independently from one institution to another, accessibility and discoverability vary widely in the GLAM domain [@fagervingWikidataAuthorityControl2023]. Wikidata is thus used either to publish digital identifiers for cultural heritage objects—enriched with LOD for the first time—or to enhance metadata by linking institutional records to Wikidata, improving visibility and interoperability [@candelaSystematicReviewWikidata2024].

Wikidata also plays a *connective role*. Its structure as a knowledge graph and its alignment with LOD principles allow it to act as a bridge between otherwise siloed datasets. By assigning persistent identifiers and promoting alignment across vocabularies and standards, Wikidata enables interoperability between different projects and institutions.

<!--@max: en gros, t'as les projets DH où WD est un provider et les GLAM où WD est une plateforme ; pourquoi pas, mais il faut aller plus loin si on dit ça selon moi ; ça se défent, mais avec plus d'arguments. qu'en penses-tu ?
Est-ce qu'on veut définir LOD ? Donner un bête exemple ?--> 

## Wikidata as a linking hub

One of the key benefits of Wikidata, as identified by many DH projects and GLAM institutions, is in its function as a hub for linking heterogeneous external resources and datasets [@neubertWikidataLinkingHub2017]. This is achieved through the creation of external *identifier properties*, which connect entities across different databases to their corresponding Wikidata items.

Take, for example, the case of Megara, an ancient Greek πόλις (*pólis*) located in the northern part of the Isthmus of Corinth. Its Wikidata item<!--@max, entry?--> ([Q42307600](https://www.wikidata.org/wiki/Q42307600)) is linked to a wide range of sources, including dictionaries, library catalogues and domain-specific databases on Greco-Roman antiquity, such as [Pleiades](https://pleiades.stoa.org/places/570468), [ToposText](https://topostext.org/place/380233PMeg) and [MANTO](https://manto.unh.edu/viewer.p/60/2616/object/6580-9619397). Through such links, Wikidata facilitates seamless cross-referencing and acts as a form of authority control [@fagervingWikidataAuthorityControl2023]. As LOD is designed to enrich data with contextual relationships, it becomes much more efficient to enrich a dataset either directly through Wikidata or through cross-queries across databases all linked to a common Q-item.

Some scholars have gone further, suggesting that Wikidata should not only serve as a hub for linking external identifiers, but should actually function as *the* reference identifier [@vanveenWikidataIdentifierIdentifier2019]. The multiplication of identifiers for the same entity (such as [Megara](https://www.wikidata.org/wiki/Q42307600)) can lead to confusion and poor data reconciliation over time. Adopting Wikidata as a universal identifier could offer several benefits: a unified description model, a single SPARQL endpoint and API for querying, and a sustainable infrastructure for data access and storage.

While this position may seem more radical, it highlights another important aspect of Wikidata's relationship with external resources: that of reciprocal contribution. As demonstrated in a paper on the interaction between Wikidata and VIAF --- a global platform that aggregates name authority files from multiple institutions --- bi-directional comparison and contribution can improve data quality on both sides [@bianchiniVIAFWikidataComplementary2021]. In this way, GLAM institutions such as libraries can not only contribute to Wikidata, but also benefit from it, strengthening a collaborative ecosystem of knowledge validation and enrichment.<!--@max, dernière phrase ok ou too much?--> 

<!--@max il est super l'exemple de Megara - merci. Il est pas mal ce passage. Puis en fait ce dernier paragraphe, ça amène ce qu'on fait avec l'AP.. Non? Je m'arrête sans doute ici pour ajd.-->

## Authority on Digital Platforms

This brings us to a central question: how can academic projects and Wikidata benefit from one another when unequal hierarchies of authority persist between these platforms? Indeed, there is a clear distinction between contributions from experts --- scholars, government bodies, or institutions --- and those from non-experts, such as general Wikidata editors. In academia, authority is frequently equated with expertise and influence, recognized and exerted within the boundaries of specific disciplines. Outside academia, institutions such as governments or GLAM organizations are similarly perceived as authoritative sources. Within any scholarly domain, certain individuals --- by means of influential publications or institutional standing --- are considered the custodians of knowledge. This interpretation of the authoritative figure typically establishes a top-down hierarchy, privileging traditional producers of knowledge --- positioning them as its sole custodians. <!-- @max : un peu changé ici, ok ? fini ici-->

We argue that this top-down hierarchy is contextual and is not always what is best for knowledge dissemination, especially fort digital platforms. As collaborative, crowdsourced, or peer-contributed platforms such as Wikidata increasingly establish themselves as new forms of authority both within and beyond academia, they raise important questions about the seal of authority and the reliability of the data they provide. This is primarily due to the fact that, in most cases, anyone can contribute to these platforms, which leads some to question the data's quality.

Thus, the status of Wikidata's editors as an authority figure is questioned because they are mostly seen by scholars and professionals as "amateurs".^[We define "amateur" as a socially engaged non-professional actor who, outside formal institutional frameworks, contributes to cultural, artistic, or documentary activities—often via participatory digital platforms. This figure is usually defined by a high level of self-taught expertise, an individual pursuit of excellence, a paradoxical sociability built on both emancipation and community, and a privileged relationship with digital platforms as new spaces for recognition and knowledge production see @severoLimperatifParticipatifInstitutions2021] Despite the increasing involvement of non-professionals in cultural initiatives, particularly on digital platforms, their contributions are still often perceived as less authoritative and must be validated by professionals to be considered reliable. This dynamic creates tensions between new actors of knowledge creation and prior groups that still are ambiguous about how to integrate them.

In the case of Wikidata, this manifests in conflicting perceptions of authority: while the platform encourages collaborative knowledge production and open participation, its data is often deemed trustworthy only when curated or approved by recognized experts. Studies have shown that, while there is still room for improvement in Wikidata’s data, the platform is increasingly recognized as a high-quality knowledge graph—one whose quality is context-dependent and must be assessed on a case-by-case basis [@piscopoWhatWeTalk2019; @shenoyStudyQualityWikidata2022; @zhaoSystematicReviewWikidata2023]. Its growing community actively contributes to its enrichment, while control mechanisms such as ShEx Schemas are gradually being implemented to ensure that Wikidata items conform to data models collaboratively defined by the community ([on Shape Expressions (ShEx) Schemas in Wikidata, see @thorntonUsingShapeExpressions2019; @thorntonEncodingArchaeologicalData2024]). These community-driven standards not only support data consistency but also reflect the platform's commitment to a decentralized yet structured form of knowledge governance. 

To this end, one of the best ways to ensure the quality and relevance of Wikidata is not merely to assess it from the outside, but rather to contribute directly to it. Through engagement with the platform—making statements, creating data models, correcting mistakes, and arguing over ontologies—researchers, cultural organizations, and "amateurs" can directly shape the knowledge graph. Rather than viewing Wikidata as a finished product to be critiqued, it becomes an open and participatory space where quality is a byproduct of collective interaction.

Another way to reconceptualize and test the notion of authority in DH projects is to fully integrate Wikidata at the core of their infrastructures—not simply as an external reference point, but as a foundational layer of data modeling, curation, and publication. In doing so, the authoritative role traditionally held by academic experts is shared with Wikidata editors. This shift reframes authority not as a fixed attribute of disciplinary recognition, but as an emergent property of collaborative knowledge practices. It also requires researchers to reconsider their position—not above or outside the platform, but alongside a distributed network of contributors who co-construct meaning, value, and trust in data.

In order to better understand these issues, we turn to our case-study, the AG project. We will explore how the AG project is building its digital platform through collaborative participation, collective intelligence, and Wikidata to question the status of authoritative figure in academia.

## Context

Since 2014, Marcello Vitali-Rosati and his team have been developing a digital and collaborative edition of the *Greek Anthology* [@verstraetePassesPresentsAnthologiques2024; @verstraete2024; @vitali-rosatiLepopeeNumeriqueLAnthologie2021; @mellet2020; @vitali-rosatiEditorializingGreekAnthology2020]. The project was born out of the need to index and make accessible this foundational corpus, which gathers nearly all the known epigrams of ancient Greek literature. This project has led to [the creation of a platform](https://anthologiagraeca.org/). Drawing on the contributions of a wide range of collaborators, it provides, for each epigram a cluster of information. Each epigram, thus, has its own page where one can find (1) its position in the *Palatine* manuscript (the *codex Palatinus graecus* 23, the principal testimony for the *Palatine Anthology*), retrieved via the IIIF protocol through the Heidelberg Library’s annotation tool linked to its API, (2) multiple translations in various languages, (3) various keywords (author, cities and other thematic keywords), (3) commentaries, (4) internal and external references, and (5) cross-alignments between translations. [A REST API is available](https://anthologiagraeca.org/api/) for querying the dataset.

This case-study focuses specifically on the use of keywords—covering entities such as (a) authors, (b) cities, and (c) others keywords collections divided in sections like deities, epithets, and epiclesis -- [the full list can be found on the website](https://anthologiagraeca.org/keywords/). As part of the project’s development, we introduced a rule requiring all keywords to be linked to Wikidata: any new keyword must be associated with a corresponding Wikidata identifier. This policy prompted a comprehensive reconciliation of our existing metadata with the Wikidata knowledge base.

## History of the platform(s) 

Since 2014, our team has been developing a digital editorial model tailored to the *Greek Anthology*, an ancient corpus, similar to a fragmentary one. Early stages of the project focused on exploring how digital tools could enhance both access to and understanding of that material. Initial prototypes—such as a SPIP-based website—provided a foundation for collaborative enrichment and allowed us to begin identifying the technical and hermeneutic challenges of such an edition.

These early experiments revealed that designing a digital edition involves more than providing access (@sahle_2016): it requires a coherent epistemological model to structure the relationships among texts, editions, translations, annotations, and contributors. Over time, the platform evolved to support collaborative editing, allowing users to contribute translations, metadata, and commentary: that is when the platform [*Anthologia Palatina*](https://anthologia.ecrituresnumeriques.ca/home) was created. Yet, as the project expanded and new collaborators joined, the limits of the initial technical infrastructure became increasingly apparent—particularly regarding multilingualism and the lack of stable identifiers for core entities like authors, cities, or any kind of tag represented by a keyword.

Building on an initial REST API, a second platform was developed -- [Anthologia graeca](https://anthologiagraeca.org/), [augmented with an API](https://preprod.anthologiagraeca.org/api/). It uses GraphQL and the backend schema is implemented using Django, a Python-based Web framework. We focused on collaborations (with Perseus, Perseids, the Library of Heidelberg, by example), highlighting the importance of strong data structuring and interoperability, core principles in the Digital Classics community. Our model had to be compatible with broader efforts in open scholarship and heritage valorization. The platform introduced a more granular editorial model centered on the epigram as a fundamental unit. This new platform adopts a semantic Web approach and is grounded in the systematic use of Wikidata identifiers^[Note that all data from previous platforms have automaticaly been imported into this one, though not all entities are currently linked to Wikidata—an ongoing task. This transition reflects our evolving editorial model: one that is increasingly open, decentralized, and connected to the wider ecosystem of digital knowledge production. Another second note is that the project is not finished — and never will be. This is not just a matter of ongoing development; it’s inherent to the nature of the corpus itself. It’s an anthology — a form that, by definition, resists closure. New readings, translations, annotations, and connections will always be possible. At present, nearly all the epigrams are available on the platform, but not all of them. Some are still being reviewed, others are pending transcription or metadata enrichment. And beyond the texts themselves, the work of annotation, translation, and linking — especially through tools like Wikidata — opens up an infinite horizon of contributions. The platform is designed to remain open, both structurally and epistemologically, to future layers of meaning and interpretation.], marking a significant evolution in our editorial framework. This decision is a turning point. Not only does it resolve earlier issues around entity identification, but it also reaffirms the project's original commitment to collaborative editorial practices: by aligning with Wikidata, we ensure that each new contribution is embedded in a broader, federated knowledge network.

## The Authors of the *Greek Anthology*

Wikidata thus plays a central role in the AG project. From the new platform on, all new keywords used to annotate the platform are created via a Wikidata URI -- note that some old keywords still have not been linked to a Wikidata ID yet, as we said above. This integration proved particularly useful in addressing inconsistencies within our list of authors. Since both Wikidata and our data model are multilingual, discrepancies such as missing authors, duplicate entries, and inconsistent information across languages were directly reflected on our platform (https://anthologiagraeca.org/authors/). To resolve these issues, we first ensured that all authors on the platform had a Wikidata URN. We then expanded our contribution by searching for author names in multiple languages (French, English, Italian, Ancient Greek, and Latin) and adding them to Wikidata. Once this information was uploaded, the Wikidata community quickly reviewed and refined our data to align it with their standards. This process not only enhanced our own dataset but also strengthened Wikidata’s overall accuracy and consistency.

:::{.callout-important}
## TO DO  
- Chantier Auteurs: retour d'expérience? méthodo? stat(-ish)?
- Interactions avec la communauté 
:::

## Quelques problématiques 

### On co-existing informations and world visions 

:::{.callout-important}
## To add (?)
- Coexistence des informations ? 
- Diversité des visions du monde ? 

> peut-être exemplifier avec le label officiel pour les alternatives label ? (genre, "je veux que ma data soit le vrai label officiel et pas relégué à un label alternatif")
:::

### Wikidata as a multilingual authority 

:::{.callout-important}
## To add (?)
- à relier aux auteurs surtout ? 
:::

### On delegating the curation of academic data 

As this example shows, because we have chosen to involve a wider community as an authority figure, the AG project is no longer the sole custodian of its data. By delegating part of the curatorial process to Wikidata and its contributors, we embrace a model of distributed authority that challenges traditional academic hierarchies. This delegation implies a shift not only in who validates the data, but also in how validation itself is understood — no longer as a top-down, expert-driven process, but as a collective negotiation of meaning, relevance, and accuracy. 

This shift towards distributed authority has many implications. 

What are the implications of this shift toward distributed authority. How can that shift in authority benefit academic research projects? Is Wikidata’s epistemological paradigm coherent with ours? Can we think of a generic epistemological framework to be effectively applied to specific academic endeavors?

### Collective Intelligence

This approach echoes with broader theories of collective intelligence. Collective intelligence refers to the shared or group intelligent derived from collaboration, collective work, and competition among thousands of actors working together within a common setting. Within collective intelligence, the wisdom of the crowd is considered superior to individual or isolated intelligences [@surowieckiWisdomCrowdsWhy2004]. Platforms such as Wikidata embody the best case of how community decentralized work may lead towards generating structured quality knowledge—provided that the contributions are supported by transparent rules, mechanisms of coordination, and mutual trust among contributors [@benklerPeerProductionForm2015; @buchelerCrowdsourcingOpenInnovation2010].

As Pierre Lévy argues, collective intelligence is especially interesting and valuable for digital environments [@levyLintelligenceCollectivePour1994]. Collaborative digital platforms are not about homogenizing knowledge or erasing differences in expertise, but about creating a space where knowledge can circulate, evolve, and converge through dialogue and participation. In Wikidata, this manifests through talk pages, project discussions, creation or modification of items and properties, and the continuous negotiation of meanings across languages, cultures, and disciplinary boundaries. It is through this ongoing process that the authority and legitimacy of the platform are constructed—not imposed from above, but co-produced by its users.

## Conclusion 

We suggest that Wikidata is not merely a technical tool but rather a space where methodological and epistemological debates can unfold. By engaging with this dynamic, researchers can enhance their projects while contributing to the creation of a more sustainable, inclusive, and collaborative knowledge base.

:::{.callout-important}
## To add 

- our presentation invites reflection on the implications of this shift toward distributed authority. 
- How can that shift in authority benefit academic research projects? 
- Is Wikidata’s epistemological paradigm coherent with ours? 
- Can we think of a generic epistemological framework to be effectively applied to specific academic endeavors?
:::

## References