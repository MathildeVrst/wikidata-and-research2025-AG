---
title: "Authoritative Practices and Collective Validation: Wikidata within the Collaborative Digital Edition of the *Greek Anthology*"
author: 
- name: Maxime Guénette
  orcid: 0009-0006-2076-1220
  affiliation: 
  - name: Université de Montréal
- name: Mathilde Verstraete
  orcid: 0000-0003-1642-8610
  affiliation: 
  - name: Université de Montréal
center-title-slide: true
echo: true
date: 05/06/2025
date-format: long
lang: en
format:
  revealjs:
    standalone: false
    width: 100%
    height: 100%
    theme: [default, ./style/style_mono_accent.scss]
    transition: slide
    navigation-mode: linear
auto-stretch: true
preview-links: true
slide-number: true
title-slide-attributes: 
  data-notes: Hello and thank you all for being here today. I'm pleased to present part of my work on my doctoral thesis focusing on Roman religions the creation of gazetteers directly integrated into Wikidata. It should be noted, however, that we are still in the early stages of our thesis and that our conclusions are therefore still preliminary. I would also like to thank the Canadian Social Sciences and Humanities Research Council for its support and confidence in funding this project.
hide-cursor-time: 2000
embed-resources: true
scrollable: true
logo: image/Udem_logo.png
footer: Wikidata and Research, University of Florence, June 5-6 2025
css: ./style/style.css
---

## Introduction @àdécider

- Hello, we are happy to be here 
- Not a surprise, Wikidata is now a commonly used tool in the DH community 
- (Parallèles) As DH, Wikidata functions as a knowledge base, enabling a sort of collective verification and semantic linking of information.

But somehow, that creates a conflict: Unlike traditional academic publishing, where authority is centralised and often restricted to established institutions or recognised experts, Wikidata operates through a model of continuous, multilingual, and community-based editing that promotes the dissemination of free and accessible knowledge globally. This paradigmatic shift invites a fundamental rethinking of authority, editorial responsibility, and the epistemological foundations of data.

- That brings us to the question with which we will work with today: 

How, then, can expert-led projects — whether developed by academics, government agencies or GLAM institutions <!--(Galleries, Libraries, Archives and Museums)--> — work with a generalist platform such as Wikidata to generate new forms of knowledge? How do these hybrid models, which combine scholarly expertise with public participation, challenge traditional boundaries between academic and amateur contributors, and between knowledge production and validation?

- In the next 20 minutes, we will : 
  - start by exploring how the infrastructure and logic of Wikidata can be integrated into DH projects 
  - talk a bit about the Anthologia Graeca project, a collaborative digital edition of the *Greek Anthology* 
  - We will analyse how Wikidata is embedded in the project’s data model — particularly through our treatment of the keyword “authors” — and how this integration opens new spaces for knowledge production.
  - Finally, drawing on those concrete examples, we will reflect on the tensions between authority and collective intelligence that shape such initiatives, and the ways in which digital infrastructures can both challenge and extend traditional scholarly practices.

## Wikidata and Digital Humanities @maxime 

:::{.columns}
:::{.column width="70%"}
- Wikidata is a major knowledge graph for structuring and sharing data

- DH projects use it to publish Linked Open Data without technical barriers

- GLAM institutions rely on it for metadata curation and interoperability

:::
:::{.column}
![](./image/Wikidata_logo.png){.absolute top="10%" right="3%" height="40%" width="25%"}
![](./image/DH.png){.absolute top="45%" right="1%" height="30%" width="30%"}
![](./image/GLAM.png){.absolute top="55%" right="35%" height="35%" width="60%"}
:::
:::

:::notes
Since it was launched in 2012, Wikidata has emerged as one of the most important knowledge graphs on the Web. With increased importance for data structuring and sharing, Wikidata holds a central place in accessing and reusing knowledge.  Despite initial skepticism, it is now widely adopted in Digital Humanities (DH) as a flexible platform for publishing and using Linked Open Data without needing deep technical skills on Semantic Web standards. In the GLAM sector, which is the Galleries, Libraries, Archives, and Museums, Wikidata is used to curate metadata and publish cultural heritage records to increase discoverability and interoperability.
:::


## Wikidata as A Linking Hub @maxime 

:::{.fragment .fade-in-then-out}
![](./image/Megare.png){.absolute top="8%" left="10%" width="85%" height="85%"}
:::

:::{.fragment}
![](./image/Megare_ID.png){fig-align="center"}
:::
:::{.fragment}
![](./image/MANTO.png){.absolute top="25%" left="-0.5%" width="15%" height="20%"}
:::
:::{.fragment}
![](./image/Mythoskop.png){.absolute top="47%" left="0%" width="15%" height="20%"}
:::
:::{.fragment}
![](./image/Pleiades.png){.absolute top="76%" left="-0.2%" width="15%" height="20%"}
:::

:::notes
One of Wikidata’s major strengths, widely recognized by Digital Humanities projects and GLAM institutions, lies in its role as a central hub for linking heterogeneous datasets. This is made possible through external identifier properties, which connect Wikidata items to corresponding entities across databases.

Take Megara, the ancient Greek city, as an example. Its Wikidata item links to a variety of sources — from library catalogues to specialized databases like Pleiades, ToposText, and MANTO. These links enable cross-referencing, facilitate authority control, and support the enrichment of data through Linked Open Data (LOD). By relying on Wikidata’s Q-items, researchers can efficiently integrate and query related resources across platforms.

Some scholars argue that Wikidata should go further and become the reference identifier itself. Multiple identifiers for the same entity — such as Megara — risk fragmenting data and complicating reconciliation. Using Wikidata as a standard could offer a unified data model, a single SPARQL endpoint, and long-term infrastructure for querying and storage.

Though this position is more ambitious, it underlines an essential aspect of Wikidata’s ecosystem: reciprocal contribution. DH projects and GLAM institutions can both feed into and benefit from Wikidata, ultimately improving the quality and reach of their data.
:::

## Authority on Digital Platforms @maxime

:::notes
This brings us to a central question: how can academic projects and Wikidata mutually enrich one another, given their different systems of validation and authority? While many Wikidata editors have strong expertise, the platform is built on openness, collaborative editing, and peer consensus — rather than formal academic credentials. By contrast, academia tends to associate authority with institutional affiliation, scholarly output, and disciplinary recognition. Similarly, GLAM institutions or government agencies are seen as authoritative due to their structured oversight and perceived reliability.

These differing frameworks create asymmetries in how contributions are trusted. Academia often relies on top-down models of validation, while Wikidata operates through distributed consensus. Understanding these dynamics is essential for building stronger collaboration between both ecosystems.

We argue that traditional hierarchies are not always the most effective model for digital knowledge production. Collaborative platforms like Wikidata challenge long-standing assumptions about authority by enabling anyone to contribute. This openness raises concerns about data quality, and Wikidata editors are often viewed as amateurs or “citizen scientists.” Their work is frequently only legitimised when endorsed by academic or institutional figures.

Despite these tensions, Wikidata is increasingly recognised as a high-quality knowledge graph. Its reliability is context-dependent and must be assessed case by case. Its community plays a key role in maintaining quality, supported by tools like Shape Expressions (ShEx) that enforce data model consistency. These community-driven mechanisms represent a decentralised but structured approach to data governance.

Crucially, improving Wikidata is not just a matter of external assessment but of active engagement. Researchers, GLAM professionals, and contributors from all backgrounds can help shape the platform by adding statements, correcting errors, refining data models, and discussing ontologies. Wikidata is not a finished product but a dynamic infrastructure where quality emerges through interaction.

To rethink authority in Digital Humanities, we suggest using Wikidata not just as a reference source but as a foundational layer for data modelling, curation, and publication. In this model, epistemic authority becomes a shared process — emerging from collaboration rather than imposed from above. Academic researchers contribute alongside volunteers, curators, and technologists in shaping meaning, structure, and trust within the data.

To explore this further, we now turn to our case study: the AG project. It demonstrates how Wikidata can support participatory infrastructure and collective validation, offering a model for reshaping authority and collaboration within academic knowledge production.
:::

<!--This brings us to our central question: how can academic projects and Wikidata be mutually enriching, given the different systems of validation and recognition that operate within each other? While many Wikidata editors have deep expertise, the platform’s structure is built on principles of openness, peer consensus, and collaborative editing rather than formal academic credentials. In contrast, academia tends to associate authority with disciplinary expertise, institutional affiliation, and scholarly output. Similarly, institutions such as governments or GLAM organisations are often recognised as authoritative because of their perceived reliability and structured oversight. These different frameworks can create asymmetries in how contributions are valued and trusted: while academia often operates through top-down models of validation, collaborative platforms like Wikidata rely more on distributed forms of consensus. Understanding and negotiating these differences is key to enhance productive dialogue and collaboration between the two ecosystems. 

We argue, however, that this top-down hierarchy model is contextual and not always best suited for knowledge dissemination, particularly in the case of digital platforms. As collaborative, crowdsourced, and peer-contributed infrastructures like Wikidata increasingly assert themselves as alternative forms of authority — both within and beyond academia — they challenge conventional assumptions about data reliability and the guaranty of expertise. This is mainly because, in most cases, anyone can contribute to these platforms, leading some to question the quality of the data (Santos, Schwabe, and Lifschitz 2024). 

The status of Wikidata editors as authoritative actors is therefore often questioned. Many scholars and professionals consider them to be amateurs5 or citizen scientists rather than experts. Despite the increasing involvement of non-professionals in cultural initiatives, especially online, their contributions often remain undervalued or require validation by recognised professionals to be considered reliable. This tension highlights the ambiguous relationship between new actors in knowledge creation and traditional epistemic authorities who are still unsure about how to integrate them. 

In Wikidata, this dynamic manifests in conflicting perceptions of authority. While the platform is designed to support collaborative knowledge production and open participation, its data is frequently considered trustworthy only when curated or approved by recognised experts. Yet, recent studies suggest that although Wikidata still has room for improvement, the platform is increasingly being recognised as a high-quality knowledge graph — one whose quality depends on context and must be assessed on a case-by-case basis (Piscopo and Simperl 2019; Shenoy et al. 2022; Zhao 2023). The platform’s growing and active community contributes significantly to its data quality, while tools such as Shape Expressions (ShEx) Schemas are being implemented to enforce model conformity and internal consistency (see Thornton et al. 2019; Thornton, Seals Nutt, and Chen 2024). These community-driven standards not only support data consistency but also reflect the platform’s commitment to a decentralised yet structured form of knowledge governance. 

One of the most effective ways to ensure the quality and relevance of Wikidata is not only to assess it from the outside, but rather to engage directly with it. Through engagement with the platform — adding statements, creating data models, correcting mistakes, and discussing over ontologies — researchers, cultural institutions and engaged amateurs alike help to shape the platform and its knowledge graph. Wikidata is not a finished product to be critiqued, but an open, iterative space where quality emerges through collective interaction.

Another way to reconceptualise authority in DH projects is to integrate Wikidata not only as a reference point, but as a core infrastructural layer for data modelling, curation and publication. In this way, the authoritative role traditionally held by academic experts is distributed and shared with a broader community of Wikidata contributors. Authority is thus reframed — not as a fixed attribute derived from institutional status, but as an emergent property of collaborative practices. Such reframing invites researchers to reconsider their own position — not above or outside the platform, but alongside a distributed network of contributors who collectively construct meaning, value, and trust in data. 

In order to examine these dynamics more thoroughly, we now turn to our case study: the AG project. We will examine how the project builds its digital infrastructure around Wikidata, collective intelligence and participatory practices to challenge and reshape the status of authoritative figures within academic knowledge production.-->



## A collaborative and digital edition of the *Greek Anthology* @mathilde

- Canada Research Chair on Digital Textualities 
- Fundings (SSHRC) ;
  - Insight Development (2017-2019)
  - Insight (2019-2025)
  - 2 Connections (2022, 2024)
- Large team :
  - Main researchers : M. Vitali-Rosati, E. Bouchard, C. Raschle
  - Coordinator : M. Verstraete, W. Bouchard
  - Technical development : D. Larlet, S. Rubio, É. Guicherd
  - Editors : L. Capelo, M. Guénette, É. Bernaer, ... 
  - Partners : CRIHN, GREN, Perseus, Perseids, Heidelberg’s Library, Liceo classico S. di Cagnazzi (Bari), University of Naples, ... 
  - Many collaborators ...

:::notes

But the case study that brings us here and on which our reflection is growing from is the Anthologia Graeca project. Let me tell you a bit more about this. 
The AG project is led by Marcello Vitali-Rosati at his CRC Chair on Digital Textualities. The co-researchers are Christian Raschle and Elsa Bouchard. You can see on the screen that they are assisted in this task by a consequent and varied team: professors, students at different levels of study (from UdeM and Naples), Italian high-school students, institutions such as the Heidelberg library, and so on. This project is made possible by several SSHRC grants.

:::

## Project's corpus 

- Collection of ancient Greek epigrammatic poetry
- Classical to Byzantine periods (= 15 centuries of epigrammatics)
- < successive compilations
- *Open* corpus:
  - *AG* = *Palatine Anthology*^[Heidelbergensis Palatinus graecus 23, X^th^ c.] + *Appendix Planudea*^[Marcianus gr. 481, 1299]
  - According to our API, 4,134 epigrams, by 311 authors


:::notes

A few words about the corpus under consideration.

Traditionally, the name *Palatine Anthology* is given to the  compilation provided by the *codex palatinus graecus* 23, a 10th century manuscript preserved in Heidelberg.

What we call the *Greek Anthology* is broader in scope, and is intended to include all the epigrams that have come down to us from  Antiquity to the Middle Ages; generally speaking, it comprises the 15 books of the *Palatine Anthology* I just mentioned, augmented by the Appendix Planudea, and, possibly, various appendices of epigrams collected here and there.

The Greek Anthology comprises over 4,000 epigrams, written by more than 300 authors over 15 centuries of Greek literature, from the 6th/5th BC to the 10th AD.

The first platefoms created in the course of the project were named adter the *Palatine Anthology*. In a second phase, we  extended it to cover the entire *Greek Anthology*, in keeping with this dynamic of an open corpus.

:::


## Project's goals 

- [A *hub* for the *Greek Anthology*]{.smaller} : Manuscript, Texts (in many languages), Keywords, Comments,... 

::::{.columns}
:::{.column width="50%"}
- La plateforme : <https://anthologiagraeca.org/>
:::
:::{.column width="50%"}
- L'API : <https://anthologiagraeca.org/api/> 
:::
::::

<video  autoplay loop muted>
  <source src="image/plateforme.webm" />
</video>


:::notes

The project was pseudo-officially born in 2014, when MVR was looking for an epigram he had studied in high school and whose number he had forgotten. Quite a few resources were available on the Web, the Perseus Digital Library had the Greek texts, the manuscript had already been digitized by Heidelberg, and a few scattered pages offered commentaries... But the main problem was the lack of systematic indexing.

As a result, the project developed on several different platforms. Today, we have a platform deployed on a Django framework (python, interoperable) with an API (in concrete terms, this means that our data can be easily retrieved by anyone, in interoperable formats).

Our aim is to bring together, for the epigrams, the images of the manuscript, texts (whether in Greek or other languages, whether official or personal translations), keywords, linked to Wikidata -- again for interoperability reasons -- comments, references to external content (weak links), etc. The platform isn't finished yet. 
The platform isn't finished: from a content point of view, there's still a lot of data missing, we can't link the images from Suppl. gr. 384 to the platform at the moment, but the aim would be to add that one, other manuscripts (the minor sylloges, for example), etc. From a platform point of view, we still have progress to make: we need to improve the references to editions, plan to implement a search engine, and so on.

:::

## A few words on the previous platforms 

- experimentation is part of the project 
- corpus : fragmentary and complex transmission 
- Different platforms: 
  - SPIP 
  - > designing a digital edition involves more than providing access to texts (Sahle 2016) 
  - Anthologia Palatina (allowed collaboration) 
  - Anthologia graeca (collaboration, API, multilingual support)

::: notes
From the beginning, the aim was not only to provide access to these texts, but also to experiment with a digital editorial model suited to their fragmentary nature and complex transmission history.

Early stages of the project focused on exploring how digital tools could enhance both access to and understanding of that material. Our first prototype — a SPIP-based website — provided a foundation for collaborative enrichment and allowed us to begin identifying the technical and hermeneutic challenges of such an edition.

These early experiments revealed that designing a digital edition involves more than providing access to texts (Sahle 2016): it requires a coherent epistemological model to organise the relationships among texts, editions, translations, annotations, and contributors.

As the project progressed, the platform evolved to support collaborative editing, allowing users to contribute translations, metadata, and commentary: that is when the platform Anthologia Palatina was created. Yet, as the corpus expanded and new contributors joined, the limits of the initial infrastructure — particularly in terms of multilingual support and stable identification of entities — became increasingly apparent.

In response, a last platform was developed: Anthologia Graeca, augmented by an API, and based on a backend architecture implemented in Django, a Python-based web framework.

:::

## The platform's keywords 


- Présenter le projet 
- Présenter l'historique des plateformes 
- Parler rapidement des partenaires éventuellement (ou pas) 
- Keyworkds dans l'AG 
<!--
## The Authors of the *Greek Anthology* @mathilde

- On va revenir sur la réalisation d'un chantier qui a été particulièrement long: celui du "nettoyage" des auteurs présents jusqu'alors sur la plateforme. 
- Pour la plupart, assez facile, pour d'autres, beaucoup moins : 

### Phanias @mathilde

### Diodoros @mathilde

### Dionysios @mathilde

### Archias @mathilde


- Marcello voulait aussi aller plus loin en ajoutant les floruit des auteurs etc, ce que j'ai refusé (manque de sources) -- Maxime a dit qu'on pouvait utiliser les références (dont j'admets ne pas avoir connaissance à l'époque, oups) -> à voir, un jour peut-être 
- Wikidata utilisé dès lors pour des connaissances qui sont relativement fragmentaires à l'image de notre objet d'étude 
-->

## Some comments on the outcome and future work @mathilde 

- Faire la même chose pour les autres types de mots-clés (villes -- presque fini) et les personnages, les thèmes, etc. ce qui fait émerger de nouvelles questions méthodologique etc (donner les exemples)
- travail en cours, on est heureux d'avoir vos retours dessus et on veillera à les intégrer à notre pratique 

## Conclusion @maxime

<!--Wikidata is not just a technical tool for data storage and retrieval; it is a dynamic epistemic space where academic knowledge is collaboratively shaped, revised, and legitimised. By delegating (while taking part of) some of our curatorial authority to Wikidata, the AG project participates in a broader shift towards distributed models of knowledge production (Benkler, Shaw, and Mako Hill 2015; Bücheler et al. 2010). This delegation does not imply an abandonment of academic rigor, but rather a reconfiguration of expertise — one that recognises the value of collective intelligence (Lévy 1994) and the potential of community- driven platforms to maintain high-quality, multilingual, and interoperable data (Surowiecki 2004). 

The implications of this shift are manifold. It invites researchers to rethink their role not only as producers of content, but also as facilitators of open, dialogical knowledge systems. It also raises critical questions: To what extent can academic standards be reconciled with the epistemological norms of a platform like Wikidata? How do we balance openness with accuracy, and participation with control? Far from erasing these tensions, the integration of Wikidata into our project foregrounds them — and in doing so, creates an opportunity for scholars to collectively reflect on the processes of validation, authorship, and authority.

Ultimately, we suggest that embracing platforms like Wikidata means accepting that academic knowledge is always provisional, situated, and co-produced. It is a move toward a more resilient and plural form of scholarship — one that recognises the potential of the many without losing sight of the responsibility of the few.-->

:::notes
In conclusion, Wikidata is not just a technical tool — it is a collaborative epistemic space where academic knowledge is shaped, revised, and legitimised. In the AG project, we delegate part of our curatorial authority to Wikidata, embracing a shift toward distributed models of knowledge production. This does not weaken academic rigour but redefines expertise through collective intelligence and the potential of community-driven platforms to support high-quality, multilingual, interoperable data.

This shift challenges researchers to act not only as content producers but also as facilitators of open knowledge systems. It raises key questions: Can academic standards align with Wikidata’s norms? How do we balance openness with accuracy?

Rather than resolving these tensions, integrating Wikidata foregrounds them — inviting reflection on validation, authorship, and authority. Embracing such platforms means acknowledging that scholarship is always provisional, situated, and co-produced. Thank you!
:::