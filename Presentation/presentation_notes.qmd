---
title: "Authoritative Practices and Collective Validation: Wikidata within the Collaborative Digital Edition of the *Greek Anthology*"
author: 
- name: Maxime Guénette
  orcid: 0009-0006-2076-1220
  affiliation: 
  - name: Université de Montréal
- name: Mathilde Verstraete
  orcid: 0000-0003-1642-8610
  affiliation: 
  - name: Université de Montréal
date: 05/06/2025
date-format: long
lang: en
format: pdf
--- 

## Title page @Max

Hello, and thank you all for being here today. We’re excited to share with you some key insights from our recent work Greek philology and Wikidata <!--particularly within the framework of a collaborative digital edition of the *Greek Anthology*.-->

## Introduction @Max @Math 

The management and preservation of research data in the Humanities increasingly raise questions concerning their sustainability, accessibility, sharing, and validation. 

In this context, Wikidata stands out as a powerful and collaborative platform. By challenging traditional models in which researchers act at the same time as producers and gatekeepers of authority, Wikidata reconfigures these issues and fosters new paradigms of collaborative knowledge production. 

Within the framework of Digital Humanities (DH), which often emphasises open processes, data interoperability and collective engagement, Wikidata functions as a knowledge base, enabling a sort of collective verification and semantic linking of information. Unlike traditional academic publishing, where authority is centralised and often restricted to established institutions or recognised experts, Wikidata operates through a model of continuous, multilingual, and community-based editing that promotes the dissemination of free and accessible knowledge globally. 

This paradigmatic shift invites us to rethink authority, editorial responsibility, and even the epistemological foundations of data. 

How, then, can expert-led projects — whether developed by academics, government agencies or GLAM institutions — work with a platform such as Wikidata to generate new forms of knowledge? How do these hybrid models, which combine scholarly expertise with public participation, challenge traditional boundaries between academic and *amateur* contributors, and between knowledge production and validation?

## Overview @Max 

In this talk, we explore how the infrastructure and logic of Wikidata can be integrated into DH projects (**Slide**).

We'll start by situating Wikidata within the broader landscape of DH initiatives (**Slide**). Then we'll turn to *Anthologia Graeca* as a case study, and look more closely at how Wikidata is embedded in the project’s data model — particularly through our treatment of the keyword “authors” — and how this integration opens new spaces for knowledge production (**Slide**). 

Finally, drawing on those concrete examples, we will reflect on the tensions between authority and collective intelligence that shape such initiatives, and the ways in which digital infrastructures can both challenge and extend traditional scholarly practices.

## Wikidata and Digital Humanities @Max

Since it was launched in 2012, Wikidata has emerged as one of the most important knowledge graphs on the Web. With increased importance for data structuring and sharing, Wikidata holds a central place in accessing and reusing knowledge. 

Despite initial skepticism, it is now widely adopted in DH as a flexible platform for publishing and using Linked Open Data (LOD) without needing deep technical skills of Semantic Web standards. In the GLAM sector, so Galleries, Libraries, Archives, and Museums, Wikidata is often used to curate metadata and publish cultural heritage records to increase discoverability and interoperability.

## Wikidata as A Linking Hub @Max

One of Wikidata’s major strengths, widely recognized the digital community, lies in its role as a central hub for linking heterogeneous datasets. This is made possible through external identifier properties, which connect Wikidata items to corresponding entities across databases.

Take for example Megara, an ancient Greek city near Corinth. Its Wikidata item links to a variety of sources — from library catalogues to specialized databases like MANTO (**Slide**), Mythoskop (**Slide**), and Pleiades (**Slide**). These links enable cross-referencing, facilitate authority control, and support the enrichment of data through Linked Open Data (LOD). By relying on Wikidata’s Q-items, researchers can efficiently integrate and query related resources across platforms.

Some scholars argue that we should go even further and make Wikidata the unique reference identifier. Multiple identifiers for the same entity — such as Megara — risk fragmenting data and complicating reconciliation. Using Wikidata as a single ID could offer a unified data model, a single SPARQL endpoint, and a long-term infrastructure perrenity for querying and storage.

Although this position is more ambitious, it underlines an essential aspect of Wikidata’s ecosystem: reciprocal contribution. DH projects and GLAM institutions can both feed into and benefit from Wikidata, ultimately improving the quality of each others data.

## Authority on Digital Platforms @Max

This brings us to a central question: how then can academic projects and Wikidata mutually enrich one another, given their different systems of validation and authority? While many Wikidata editors have strong expertise, the platform is built on openness, collaborative editing, and peer consensus — rather than formal academic credentials. By contrast, academia tends to associate authority with institutional affiliation, scholarly output, and disciplinary recognition. Similarly, GLAM institutions or government agencies are seen as authoritative due to their structured oversight and perceived reliability.

These differing frameworks create asymmetries in how contributions are trusted. Academia often relies on top-down models of validation, while Wikidata operates through distributed consensus. Understanding these dynamics is essential for building stronger collaboration between both ecosystems.

We argue that traditional hierarchies are not always the most effective model for digital knowledge production. Collaborative platforms such as Wikidata challenge long-standing assumptions about authority by enabling anyone to contribute. This openness raises concerns about data quality, and Wikidata editors are often viewed as amateurs or “citizen scientists.” Their work is frequently only legitimised when endorsed by academic or institutional figures.

Despite these tensions, Wikidata is increasingly recognised as a high-quality knowledge graph. Its reliability is context-dependent and must be assessed case by case. Its community plays a key role in maintaining quality, supported by tools like Shape Expressions (ShEx) that enforce data model consistency. These community-driven mechanisms represent a decentralised but structured approach to data governance.

<!--Crucially, improving Wikidata is not just a matter of external assessment but of active engagement.-->  Wikidata is not a finished product but a dynamic infrastructure where quality emerges through interaction. Researchers, GLAM professionals, and contributors from all backgrounds can help shape the platform by adding statements, correcting errors, refining data models, and discussing ontologies. 

To rethink authority in DH, we suggest using Wikidata not just as a reference source but as a foundational layer for data modelling, curation, and publication. In this model, epistemic authority becomes a shared process — emerging from collaboration rather than imposed from above. <!--Academic researchers contribute alongside volunteers, curators, and technologists in shaping meaning, structure, and trust within the data.-->

To explore this further, we now turn to our case study: the *Anthologia Graeca* project. We will examine how the project builds its digital infrastructure around Wikidata, collective intelligence and participatory practices to challenge and reshape the status of authoritative figures within academic knowledge production.

## A collaborative and digital edition of the *Greek Anthology*  @Math

Let me now introduce the case study behind today’s reflections — the *Anthologia Graeca* project, a collaborative digital edition of the *Greek Anthology*. <!-- Je dis déjà un peu dans le dernier para de la dernière section que je l'introduit, tu peux peut être dire genre: The Anthologia Greca project is based on the Greek Anthology, a vast... -->

The *Greek Anthology* is a vast and fragmentary collection of of epigrammatic poetry -- mainly, short poems. These epigrams are grouped into thematic books and span over fifteen centuries of literary production, from Classical Greece to the Byzantine period. Rather than being the work of a single author or moment, the *Anthology* is the result of ongoing compilation, transmission, and reorganization.

This corpus is by nature open-ended — shaped by layers of compilation and reassembly over time. 

Our aim was to design a digital platform that could reflect this dynamic, evolving structure — one that embraces the *Anthology*’s fluidity instead of imposing artificial boundaries.

## Project Origins and Team 

The project was launched in 2014 by Marcello Vitali-Rosati, as part of the Canada Research Chair in Digital Textualities, with collaborators including Christian Raschle <!-- lol tu peux enlever Raschle si tu veux (ou pas, sens toi libre), il a rien glandé--> and Elsa Bouchard. I’ve been the project coordinator since 2021. 

Supported by several grants from the Social Sciences and Humanities Research Council of Canada, it brings together a wide network of scholars, developers, and students — from the University of Montreal, the University of Naples, and even high school students from Bari. Institutional partners include the Interuniversity Research Centre on the Digital Humanities, the Research Group on Scholarly Editions in a Digital Context, Perseus, and the Heidelberg University Library. <!-- Y'a moyen de dire que le projet rassemble des uni, Altamurra et des projets/plateformes partenaires en une phrase je crois-->

From the beginning, the project has been grounded in the principles of open science: sharing data, working collaboratively across institutions and disciplines, and building tools that remain accessible and reusable. In that spirit, we turned early on to Wikidata — not only as a resource we could draw from, but as a platform we could also contribute to. This engagement has allowed us to rethink how authority and knowledge circulation function in collaborative digital scholarship.

## Platform and Goals @Math

Our goal was to build a digital infrastructure that acts as a central hub — bringing together information and data related to each epigram: main manuscript images, transcriptions, translations, keywords, commentaries, and references. All of this is accessible in an open and interoperable <!--platform?--> to support reuse, collaboration, and long-term accessibility.

The current platform runs on Django, with a public API, and offers access to over 4,000 epigrams attributed to more than 300 authors. While the platform is still evolving — with ongoing work on metadata, referencing, and editorial enrichment — its purpose remains clear: to support collaborative scholarship, semantic annotation, and multilingual engagement with our corpus.

One important aspect I want to highlight is that the project didn’t start with a fixed editorial model — it evolved over time, across several platforms. As both our technical and philological understanding matured, so did our goals. This evolution played a crucial role in the reconciliation work I’ll describe in a moment.

For instance, in our current platform, adding a new keyword now requires linking it to a corresponding Wikidata identifier. But much of the data that we imported from previous versions — built before we implemented this rule  — lacks those identifiers. This mismatch between imported data and current editorial standards is precisely what made reconciliation necessary. 

## The platform's keywords @Math 

Our platform uses keywords to describe and organize the content of each epigram. These keywords fall into several categories:

1. Authors to whom the epigrams are attributed ;
2. Cities, about which the epigram is about<!--loin d'être souvent le cas, j'enlèverais et je dirais juste cities-->;
3. And a broad set of general keywords, which include things like collections, deities, cited poets, famous historical or mythical figures, metrical forms, etc. 

The first step of our reconciliation work focused on the authors — both because of their centrality in the corpus and because they provided a manageable entry point for aligning our data with Wikidata.

I'll start by walking you through that process, and then briefly say a few words on the others.

## Reconciling Keywords with Wikidata @Math

During the process of reconciling our authors' names with their Wikidata identifiers, we took the opportunity to check the attributions that had been made on our platform and to add the authors' names in different languages to Wikidata.

To do so, we began by exporting the authors into a spreadsheet. That gave us a first overview of inconsistencies — duplicates, spelling variants, ambiguous attributions. We added their names in Latin, Ancient Greek, English, French, and Italian.

Our goal -- and this is important -- was to push cleaned data to Wikidata, and then pull it back into our platform -- once structured, normalized, and enriched. But as we engaged with Wikidata, we quickly realized that it wasn’t just a passive repository. The community was highly responsive. Feedback came fast -- sometimes technical, always helpful -- and it forced us to reflect critically on our editorial assumptions.

Let me share two quick examples that illustrate the kind of decisions we had to make.

## Diodoros (ambiguous entries) @Math

Our database initially listed four variants of the name Diodoros, with some entries referring to historical figures that could or could not be the same (“Diodorus, Diodoros”, “Diodore de Tarse, Diodoros le Grammairien”, “Diodoros Zonas de Sardes”, and a lowercase entry, “diodorus”). The Belles Lettres edition mentions at least three poets named Diodoros — and in some cases, it’s impossible to tell which one is being referenced. 

> Diodoros. Trois poètes de la Couronne de Philippe ont porté ce nom : Diodore Zonas, de Sardes, orateur célèbre du temps de la guerre de Mithridate ; un autre Diodoros de Sardes ; enfin, Diodoros de Tarse. On ne sait auquel attribuer les épigrammes où le gentilicium n’est pas spécifié. (Waltz 2003, II:142–43)

So we decided to keep separate entities when possible and created a generic “Diodoros Epigrammaticus” entry (in line with Perseus conventions) for unattributed cases. This solution may not be perfect, but it’s honest — and it lets uncertainty remain visible rather than artificially resolved.

## Dionysos (uncertain attribution for common names) @Math

The same logic applied to Dionysios, illustrating the difficulties posed by common names in the manuscript tradition. Many epigrams are attributed simply to “Dionysios”, with no further context -- we don't even know how many distinct authors are represented. 
Instead of choosing arbitrarily, we retained specific identities when clear (Dionysius of Andros, Dionysius of Cyzicus, Dionysius of Rhodes and Dionysius the Sophist), and created a catch-all “Dionysios” entity where attribution was unclear. Again, the idea was to represent uncertainty, not erase it.

This raises the question of “how do we make ambiguity and uncertainty readable, especially in a digital context?”

## Gain for our platform and for Wikidata @Math

What started as metadata cleaning quickly became something deeper. We improved many attributions, added inline commentary for uncertain cases (see AG X.38), created new Wikidata items, and contributed multilingual labels.

But more importantly, we encountered a series of modeling challenges that revealed the tensions between interpretive scholarship and structured ontologies.

A good example is the case of pseudo-authors. One of our entries had been labeled in Ancient Greek with the prefix Ψευδο- — following modern editorial conventions. But the Wikidata community flagged it as problematic: the prefix is rare in ancient sources and may reflect anachronistic assumptions. The label was removed — and the debate forced us to consider how editorial categories translate (or don’t) into semantic web models. 

## Other keywords and future work @Math

Beyond authors, we worked with other types of keywords. For places, we imported data directly from Wikidata. While the coordinates were very helpful, the multilingual labels were less consistent -- but we intend to add the information on Wikidata in the following months. 

Eventually, we still have to reconcile the other thematics keywords. Some of them are easy, some are not. These categories function as reading tools, but they don’t necessarily align with Wikidata’s data model. Other tags, like bad breath or drunkenness, describe literary motifs — relevant for interpretation, but difficult to represent in a structured ontology.

In short, aligning our data with Wikidata is a major step toward openness and interoperability. But reconciling this data reveals just how difficult it is to map scholarly knowledge into structured ontologies — especially when the two systems weren’t designed to work together in the first place.

## Conclusion @Math

To conclude: Wikidata is not just a technical backend. It is a collaborative epistemic space — a platform where academic knowledge is not only stored, but also negotiated, revised, and legitimized.

In the *Anthologia Graeca* project, linking our editorial work to Wikidata meant delegating part of our curatorial authority to a broader community — not as a loss of academic rigor, but as a deliberate move toward a more distributed model of expertise. A model that values scholarly precision, while also embracing the strength of collective intelligence to support high-quality, multilingual, and interoperable data.


This shift invites us to rethink our roles as researchers: not only as producers of content, but also as participants in open knowledge systems — where validation is collaborative, multilingual, and always in progress.

It also raises essential questions:
Can academic standards and open platforms like Wikidata truly align?
How do we balance transparency with control, or openness with critical nuance?

Rather than smoothing out these tensions, working with Wikidata makes them visible — and in doing so, creates a space for reflection on how knowledge is authored, validated, and shared.

Engaging with such platforms means accepting that authority in the digital age is no longer something we hold — through status, institutional affiliation, or academic citations — but something we negotiate: collectively, contextually, and in dialogue with others.

Thank you.
